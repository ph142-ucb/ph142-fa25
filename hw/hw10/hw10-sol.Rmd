---
title: "Homework 10"
author: "Your name and student ID"
date: "Today's date"
output:
  pdf_document: default
---

### Instructions 
* Solutions will be released on Tuesday, April 20
* This semester, homework assignments are for practice only and will not be turned in for marks.

```{r, warning=F, message=F, echo=F}
library(dplyr)
library(ggplot2)
library(readr)
library(ggrepel)
library(broom)
library(tidyr)
```

```{r setup, include = FALSE}
# Don't change these lines, just run them!
source("setup/hw10.RAGS.R")
```


\newpage

### Section 1: Voting during the 1992 election [21 points]

In the spirit of the upcoming 2020 presidential election, I thought it would be 
interesting to consider some historical data on voting patterns across US counties.

This code loads in the data frame `counties`:

```{r}
load("A10_counties.sav")
```

These data are from the 1992 election and looks at the percent of votes cast 
(for each county) for the `democrat` (Bill Clinton), `republican` (George Bush),
and independent presidential nominees (Ross `Perot`). 

Ideally, if you were interested in voting patterns, you might look at the 
relationship between individual characteristics and whether each individual 
voted Democrat or Republican. However, data like that is often hard to come by.
The `counties` data provide data on 3141 counties. Use `View()` to examine these
data briefly and read the labels corresponding to the variables. Note that Alaska
is not included and that two other counties with populations = 0 have also been 
excluded.

As discussed in class we have the entire population (not just a sample), so 
strictly speaking we don't need to perform statistical inference. However, we
might pretend this is a sample so that we can apply the techniques of inference 
and gain competence creating and interpeting a linear model.

\newpage

1. [2 points] Looking only at California, plot the relationship between 
the % of votes cast for the Democratic candidate (`democrat`) 
and the population density of the county (`pop.density`). Since we will only be using the counties from California, go ahead and subset the full `counties` dataset to only include observations from the state of CA. 

```{r}
counties_CA <- "SUBSET DATA HERE"

p1 <- "YOUR PLOT HERE"
p1

# BEGIN SOLUTION
counties_CA <- counties %>% filter(state == "CA")

p1 <- ggplot(counties_CA, aes(x = pop.density, y = democrat)) + 
  geom_point() 
p1
# END SOLUTION

check_problem1()
```

\newpage

2. [1 point] The above plot you made does not look very good. 
The distribution of population density is skewed right, 
with a few counties having much higher densities than the majority of counties.
To see which counties these are, we will use `geom_text_repel` from the 
library `ggrepel` (loaded at the top of this assignment). 
The template for using this function is: 
`geom_text_repel(aes(label = your_labelling_var))`. 
You will want to set the labeling variable to be the variable in the dataset
containing the county names.

```{r}
p2 <- "YOUR CODE HERE"
p2

# BEGIN SOLUTION
p2 <- ggplot(counties_CA, aes(x = pop.density, y = democrat)) + 
  geom_point() + 
  geom_text_repel(aes(label = county))

p2
# END SOLUTION

check_problem2()
```

The current issue with these data is that San Francisco 
(as you can now hopefully point out) 
has a much higher population density than other counties, 
and that generally there is a large right skew in the distribution 
of the population density variable. 

If we tried and fit a linear model to these data, it would not fit well-- because
the relationship between population density and the response variable is not 
linear. However, this is the perfect situation to try transforming the x variable.

\newpage

3. [2 points] Try adding a log-transformed version of population density to the data frame and remake your plot using this new variable. Call this new variable `log_pop_density`. Keep the population labels. Also add a smoothed fitted line:

```{r}
# uncomment the line below by deleting the pound sign
# counties_CA <- "Add new variable here"

p3 <- "YOUR PLOT HERE"
p3

# BEGIN SOLUTION

counties_CA <- counties_CA  %>%
  mutate(log_pop_density = log(pop.density))

p3 <- ggplot(counties_CA, aes(x = log_pop_density, y = democrat)) + 
  geom_point() +
  geom_smooth() +
  geom_text_repel(aes(label = county))

p3

# END SOLUTION

check_problem3()
```

\newpage

4. [4 points] Describe the relationship between the (logged) population density 
and the response variable in terms of the shape, direction, strength, and outliers.
These are concepts from Chapter 3. Calculate the correlation (round to 4 decimals) to comment on one of these aspects.

```{r}
p4 <- "CALCULATE THE CORRELATION HERE"
p4

# BEGIN SOLUTION
p4 <- counties_CA %>% summarise(cor = cor(democrat, log_pop_density))
p4 <- round(p4[[1]],4)
p4


# END SOLUTION
check_problem4()
```


[TODO: YOUR ANSWER HERE]


# BEGIN SOLUTION

Direction: There is a positive association between logged population density and 
the % of votes cast for the democratic candidate is 

Shape: Roughly linear, or slightly curved.
Outliers: No real large outliers, though SF and Orange County are a bit further
out from the rest of the points.

Strength: 0.638

The correlation between the variables is 64%, indicating a moderate positive
association.

# END SOLUTION

\newpage

5. [4 points] Run a linear model regression of the % votes cast for the democratic
candidate as a function of the population density. Make sure you get the order
of variables right in the `lm()` function! Use the `tidy()` function to show the 
slope and intercept estimates. Interpret the relationship between the logged population 
density and the response variable. (You can `View()` the data frame to make sure
you are getting your units right by checking the descriptions in the labels for 
each variable). Use another function from `broom` show the r-squared. Report and interpret this value for the model.

```{r}
lm_CA <- "YOUR MODEL HERE"

r.squared <- "Report r-squared here. Leave as decimal and round to 2 places"

# BEGIN SOLUTION
lm_CA <- lm(formula = democrat ~ log_pop_density, data = counties_CA) 
tidy(lm_CA)
model<- glance(lm_CA)
r.squared <- round(model$r.squared, 2)
r.squared
# END SOLUTION

check_problem5()
```

[TODO: YOUR ANSWER HERE]

# BEGIN SOLUTION
A one unit change in the logged population density is associated with a 
2.88 (where population density was the 1992 population per square-mile)
percentage point increase in the percent of votes cast for the democratic 
candidate.

The r-squared is 0.41, implying that 41% of the variation in percentage votes
casts is explained by the logged population density.

# END SOLUTION

\newpage

6. [4 points] Using the code learned in class, that was also shown in Lab 11, make the four plots to examine the assumptions.

```{r}

plot1 <- "Code for scatterplot here"
plot1

plot2 <- "Code for QQ plot here"
plot2

plot3 <- "Code for Fitted vs. Residuals plot here"
plot3

plot4 <- "Code for Amount explained plot here"
plot4

# BEGIN SOLUTION 
CA_augment <- augment(lm_CA)

# scatter plot
plot1 <- ggplot(CA_augment, aes(y = democrat, x = log_pop_density)) +
  geom_point() +
  geom_smooth(method = "lm", se = F) +
  geom_segment(aes(xend = log_pop_density, yend = .fitted), lty = 2) +
  theme_minimal(base_size = 15) +
  labs(title = "(a) Scatter plot")
plot1 

# QQ plot
plot2 <- ggplot(CA_augment, aes(sample = .resid)) + 
  geom_qq() + 
  geom_qq_line() +
  theme_minimal(base_size = 15) +
  labs(y = "Residuals", x = "Theoretical quantiles", title = "(b) QQplot")
plot2

## Fitted vs. residuals
plot3 <- ggplot(CA_augment, aes(y = .resid, x = .fitted)) + 
  geom_point() + 
  theme_minimal(base_size = 15) +
  geom_hline(aes(yintercept = 0)) +
  labs(y = "Residuals", x = "Fitted values", title = "(c) Fitted vs. residuals") 
plot3

## Amount explained
bolt_gather <- CA_augment %>% select(democrat, .resid) %>%
  gather(key = "type", value = "value", democrat, .resid)
plot4 <- ggplot(bolt_gather, aes(y = value)) +
  geom_boxplot(aes(fill = type)) +
  theme_minimal(base_size = 15) +
  labs(title = "(d) Amount explained")
plot4

# END SOLUTION

check_problem6()
```

7. [4 points] Comment on each of the plots and conclude about which 
assumptions appear violated vs. not violated. Don't forget to comment on the 
one assumption that cannot be investigated using plots.

[TODO: YOUR ANSWER HERE]

# BEGIN SOLUTION
- There is a violation of the assumption that the standard deviation of the response
variable are identical for all values of the explantory variable. We see here 
that as the log population density increases, the residuals become larger.
- The relationship between X and Y is approximately linear, though there is a lot
of variation around the line of best fit. (This points to the fact that though
population density is predictive of the response variable, there are other factors
that are not included in our model that have further predictive power.)
- The QQ plot looks ok. (May be interpreted as a problem with the largest residuals.
- We can't check the assumption that the points are independent using this plot.)
Here that corresponds to the counties being independent of one another. This 
model treats them as independent units. [More sophisticaled models can take the
spatial relationships between the counties into account (to account for the fact
that counties closer to each other may be more similar.)]
# END SOLUTION

\newpage


### Section 2: Abstract interpretation [5 points]
Read the following abstract and answer the questions that follow. 
J Asthma. 2018 Oct 11:1-12. doi: 10.1080/02770903.2018.1508471. [Epub ahead of print]
Impact of scenario based training on asthma first aid knowledge and skills in school staff: an open label, three-arm, parallel-group repeated measures study.
Luckie K1, Saini B1, Soo YYB1,2, Kritikos V1,3, Charles Collins JB1, Jane Moles R1.

OBJECTIVE:
To test the hypothesis that scenario-based skills training is more effective than knowledge training alone in improving the asthma first aid (AFA) skills of school personnel. Education developed specifically for non-primary caregivers such as school staff is vital to minimize the risk of mortality associated with asthma.

METHODS:
Schools were allocated to one of three arms to compare AFA knowledge and AFA skills. Arm 1 underwent conventional asthma training, arm 2 underwent scenario-based training and arm 3 had a combination of the two. Conventional asthma training involved a didactic oral presentation. The scenario-based skills training required the participant to describe and demonstrate how they would manage a child having a severe exacerbation of asthma using equipment provided. Follow-up occurred at 3 weeks post baseline and again between 3-7 months after the first training/education visit.

RESULTS:
Nineteen primary schools (204 participants) were recruited. One-way ANOVA and Bonferroni Post-Hoc Tests showed there was a significant difference in AFA skills scores between the study arms who underwent scenario-based training; arms 2 and 3 (91.5% and 91.1%) and arm 1 who underwent conventional asthma training (77.3%) (p<0.001). AFA knowledge improved significantly in all study arms with no differences between study arms. Improvements seen in both AFA knowledge and AFA skills were maintained over time.

CONCLUSIONS:
Scenario-based training was superior to conventional didactic asthma training for AFA skills acquisition and overall competency in the administration of AFA and should be included in future asthma training programs.

\newpage

8. [1 point]	Two methods of hypothesis testing (types of tests) are mentioned in the abstract.  What is the null hypothesis for each of these tests (please list in the order they are mentioned in the abstract?

$H_{0}$:  [TODO: YOUR ANSWER HERE] - one sentence only 


$H_{0}$:  [TODO: YOUR ANSWER HERE] - one sentence only 

# BEGIN SOLUTION

$H_{0}$: There is no difference between scenario-based skills training and  knowledge training alone in improving the asthma first aid (AFA) skills of school personnel.

$H_{0}$: There is no difference in the improvement of asthma first aid skills of school personnel after receiving training scenario-based skills training and a combination of didactic and skills training.

# END SOLUTION

\newpage

9. [1 point] There are two outcomes of interest in this study.  For which **outcome** would you conclude that there is a significant difference between the training groups.  

[TODO: YOUR ANSWER HERE]

# BEGIN SOLUTION

There is a significant difference in outcome between arm1 and arms2 and 3 of the training groups.

# END SOLUTION

\newpage

10. [1 point] If you were a school administrator why might you choose the arm 3 training?

[TODO: YOUR ANSWER HERE]

# BEGIN SOLUTION

Arm 3 showed a significant improvement over just receiving didactic training but it includes some components that are more traditional to other teaching scenarios. The teaching program would not need to be completely overhauled but rather just include skills-based training.

# END SOLUTION
\newpage

11. [1 point] List one question you might want to ask about the methods, sample or results that would help you interpret the findings of this study?

[TODO: YOUR ANSWER HERE]

# BEGIN SOLUTION

Possible questions could be:
1. What, if any, training had these recruits already experienced?
2. Were the participants randomized to a study arm?
3. What was the difference between arm 2 and arm 3?
4. How was improvement defined in the context of this study?

# END SOLUTION

\newpage

12. [1 point]  What is another test that could have been considered for these study data?

[TODO: YOUR ANSWER HERE]

# BEGIN SOLUTION

Two sample t test could have been considered to see if there was a difference in average improvement between arm 2 and arm 3.

# END SOLUTION

\newpage

### Section 3: ANOVA and Tukey's HSD [6 points]
**Note: This material will be taught on Monday, November 23rd**


For this question we will use the data from the NHANES survey
`
```{r read, echo=FALSE}
# Read CSV into R
nhanes <- read_csv("nhanes.csv")
head(nhanes)

nhanes <- na.omit(nhanes) #remove rows with missing values
```

\newpage

13. [1 point] Generate the mean and standard deviations in a dataframe for blood lipid level "lbdldl" by Blood pressure group "bpcat". Use dplyr functions.

```{r}
p13 <- "Your code here"
p13

# BEGIN SOLUTION
p13 <- nhanes %>% group_by(bpcat) %>% summarize(mean = mean(lbdldl), sd = sd(lbdldl))
p13
# END SOLUTION

check_problem13()
```

\newpage

14. [1 point] Create a boxplot that helps you to visualize these data.

```{r}
p14 <- "Your plot here"
p14

# BEGIN SOLUTION
p14 <- ggplot(nhanes, aes(x = bpcat, y = lbdldl)) +
        geom_boxplot()
p14
# END SOLUTION

check_problem14()
```

\newpage

15. [2 points]  Conduct an ANOVA with Tukey's HSD for these data. Assign your model to the variable `tukey`.

```{r, warning = F}
tukey <- "Your code here"
p15 <- tidy(tukey) #keep this line

# BEGIN SOLUTION
model <- aov(lbdldl~bpcat, data = nhanes)
tukey <- TukeyHSD(model, conf.level = 0.95)
p15 <- tidy(tukey)
p15
# END SOLUTION

check_problem15()

```

\newpage

16. [1 point]  What are the null and alternative hypotheses for this test?

[TODO: YOUR ANSWER HERE]

# BEGIN SOLUTION

$H_{0}$ = The average blood lipid level is equal across blood pressure groups. 

$H_{A}$ = The average blood lipid level is different for at least one of the three blood pressure groups.

# END SOLUTION

\newpage

17. [1 point]  What do you conclude from your analysis?

[TODO: YOUR ANSWER HERE]

# BEGIN SOLUTION

Since all of the confidence intervals contain 0 and none of the p-values are significant at an alpha = 0.05 level, we fail to reject the null hypothesis that the average blood lipid level is equal across blood pressure groups.

# END SOLUTION

\newpage

### Section 3: Non-parametric [3 points]
**Note: This material will be taught on Monday, November 30th**

You are testing the change in test scores following an intensive tutoring session.  
You have the following data from a small group of students each student is tested before and after the tutoring session.  
Each row represents one student.  

|Time 1   |Time 2|
|---------|------|
|65       |77    |
|87       |100   |
|77       |75    |
|90       |89    |
|70       |80    |
|84       |81    |
|92       |91    |
|83       |96    |
|85       |84    |
|91       |89    |
|68       |88    |
|72       |100   |
|81       |81    |
|---------|------|

```{r}
#this code makes a dataframe of the table you see above
test_scores <- tribble(
  ~time1, ~time2,
  65, 77,
  87, 100,
  77, 75,
  90, 89,
  70, 80,
  84, 81,
  92, 91,
  83, 96,
  85, 84,
  91, 89,
  68, 88,
  72, 100,
  81, 81)

```


18. [2 point] Calculate the appropriate non-paramentric test for these data by hand. Attach an image to show your work. Make sure to place the image in the `src` directory. Uncomment the line by deleting the pound sign. Report the p-value by saving it p18. Keep it as a decimal and round to 4 places.

```{r}
#knitr::include_graphics("src/path-to-file")
p18 <- "YOUR P-VALUE HERE"
p18

# BEGIN SOLUTION
test_scores <- test_scores %>% mutate(diff = time1 - time2)
n <- nrow(test_scores) - 1 #one obs was dropped as the difference was 0
t <- 21
mu <- (n*(n + 1))/4
mu
sigma <- sqrt((n*(n+1)*(2*n+1))/24)
sigma

z.stat <- (t - mu)/sigma
z.stat

p18 <- round(2*pnorm(z.stat),4)
p18
# END SOLUTION

check_problem18()
```


\newpage

19. [1 point] Check your work using [insert your test].test() function in R. Keep your answer as a decimal rounded to 4 decimals. Report your p-value and save it to the variable p19.

```{r, warning=FALSE}
p19 <- "Your p-value here"
p19

# BEGIN SOLUTION
wilcox.test(test_scores %>% pull(time1),test_scores %>% pull(time2), paired=T, correct=FALSE)

p19 <- 0.1579
p19
# END SOLUTION
check_problem19()
```

\newpage


### Check your score

Click on the middle icon on the top right of this code chunk (with the downwards gray arrow and green bar) to run all your code in order. Then, run this chunk to check your score.
```{r check-total-score}
# Just run this chunk.
total_score()
```

